{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ij2205_Assignment4_part3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "CmO1WEDPp1xy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3sd_AEJspQJg",
        "colab_type": "code",
        "outputId": "bf5131bd-19b3-47bb-9b54-cc523d2037fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the colors dataset\n",
        "if not os.path.exists('colors.csv'):\n",
        "  !curl -O 'https://raw.githubusercontent.com/random-forests/datasets/master/colors.csv'\n",
        "!head colors.csv"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name,red,green,blue\n",
            "parakeet,174,182,87\n",
            "saddle brown,88,52,1\n",
            "cucumber crush,222,237,215\n",
            "pool blue,134,194,201\n",
            "distance,98,110,130\n",
            "light urple,179,111,246\n",
            "east side,172,145,206\n",
            "florida seashells,250,228,199\n",
            "paris,145,167,189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mG0WnNZtmxul",
        "colab_type": "code",
        "outputId": "06a74f25-7b49-44ab-b44d-80741b4719fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "colors_rgb = []\n",
        "csv_reader = csv.reader(open('colors.csv'), delimiter=',')\n",
        "next(csv_reader) # Remove the header\n",
        "for row in csv_reader:\n",
        "    name, r, g, b = row[0].lower().strip(), int(row[1]), int(row[2]), int(row[3])\n",
        "    colors_rgb.append((name, r, g, b))\n",
        "print(len(colors_rgb), 'colors downloaded')\n",
        "print('For example', colors_rgb[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14157 colors downloaded\n",
            "For example ('parakeet', 174, 182, 87)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdIWQdlBrZXA",
        "colab_type": "code",
        "outputId": "f61e8099-95db-47f9-d248-81005ecb1e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# In this experiment, we will train a char-baed RNN to generate a line of text\n",
        "# that resembles this dataset (we'll treat each line as a string)\n",
        "sentences = []\n",
        "for row in colors_rgb:\n",
        "  line = ' '.join([str(part) for part in row])\n",
        "  sentences.append(line)\n",
        "print(sentences[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parakeet 174 182 87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_o2oIUNuyWZ",
        "colab_type": "code",
        "outputId": "c66f8c51-95cd-41f1-8d21-70625f1e0770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# vocabulary for our char-based RNN\n",
        "chars = set()\n",
        "for sentence in sentences:\n",
        "  for char in sentence:\n",
        "    chars.add(char)\n",
        "    \n",
        "# add a special char for padding\n",
        "chars.add('<pad>')\n",
        "\n",
        "vocab = sorted(set(chars))\n",
        "\n",
        "# Create a mapping from unique characters to indices\n",
        "char2idx = {u : i for i, u in enumerate(vocab)}\n",
        "idx2char = {i : u for i, u in enumerate(vocab)}\n",
        "\n",
        "# Vocab size\n",
        "vocab_size = len(vocab)\n",
        "print('vocab size:', vocab_size)\n",
        "print(vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size: 38\n",
            "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<pad>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5sdKRJ6rp8I",
        "colab_type": "code",
        "outputId": "b2e9358b-dbfd-4440-e858-95e6711dd4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# vectorize the text\n",
        "text_int = []\n",
        "for sentence in sentences:\n",
        "  int_sentence = [] \n",
        "  for c in sentence:\n",
        "    int_sentence.append(char2idx[c])\n",
        "  text_int.append(int_sentence)\n",
        "print('Vectorized sentence', text_int[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorized sentence [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0g6Do15As4yQ",
        "colab_type": "code",
        "outputId": "3966d16c-fb22-417e-c942-3cd9d0d5af5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# pad sentences to max_length\n",
        "max_length = 40\n",
        "for sentence in text_int:\n",
        "  while (len(sentence) < max_length):\n",
        "    sentence.append(char2idx['<pad>'])\n",
        "print('Padded sentences', text_int[0])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padded sentences [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-y87WF_Fw1kJ",
        "colab_type": "code",
        "outputId": "a81e058d-6d8b-4352-e832-f4e005b2b0f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# truncate all sentences to max_length\n",
        "for i in range(len(text_int)):\n",
        "  sentence = text_int[i]\n",
        "  if len(sentence) > max_length:\n",
        "    text_int[i] = sentence[:max_length]\n",
        "print(\"Truncated sentences\", text_int[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncated sentences [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mwu3FgSpxNWT",
        "colab_type": "code",
        "outputId": "950e52b2-f3e4-499c-9773-cd856a32b36f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# Create training examples / targets\n",
        "input_text = []\n",
        "target_text = []\n",
        "\n",
        "for i in range(len(text_int)):\n",
        "  inps = text_int[i][:max_length-1]\n",
        "  targ = text_int[i][1:max_length]\n",
        "  input_text.append(inps)\n",
        "  target_text.append(targ)\n",
        "  \n",
        "print(\"First training example, target\")  \n",
        "print(input_text[0])\n",
        "print(target_text[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First training example, target\n",
            "[27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
            "[12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cjyeDrvGzl8E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TT8ed7cu0w-z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, units):\n",
        "    super(Model, self).__init__()\n",
        "    self.units = units\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn1 = tf.keras.layers.SimpleRNN(self.units,return_sequences = True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "  def call(self, x):\n",
        "    embedding = self.embedding(x)\n",
        "    rnn1 = self.rnn1(embedding)\n",
        "    prediction = self.fc(rnn1)\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jA8Pssrh1NKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension \n",
        "# Here, this is basically just a trick to avoid having \n",
        "# to one-hot encode the characters\n",
        "# I don't think it will add much otherwise\n",
        "# this would be more useful if we had a much larger vocabulary\n",
        "embedding_dim = 128\n",
        "\n",
        "# Number of RNN units\n",
        "units = 256\n",
        "\n",
        "model = Model(vocab_size, embedding_dim, units)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrSRbSQk1Rcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "# Using sparse_softmax_cross_entropy so that we don't have to create one-hot vectors\n",
        "def loss_function(labels, logits):\n",
        "    return tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AILeTt71UXr",
        "colab_type": "code",
        "outputId": "30857e36-9a0d-4b90-c985-75c7c0a20bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "model.build(tf.TensorShape([BATCH_SIZE, max_length]))\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      multiple                  4864      \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       multiple                  98560     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  9766      \n",
            "=================================================================\n",
            "Total params: 113,190\n",
            "Trainable params: 113,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gjYtdulr8ukK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# Checkpoint instance\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkLMi8GI1c9b",
        "colab_type": "code",
        "outputId": "28396598-d871-4014-a94a-13303ed86718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    # initializing the hidden state at the start of every epoch\n",
        "    # initally hidden is None\n",
        "    hidden = model.reset_states()\n",
        "    \n",
        "    for (batch, (input_seq, target_seq)) in enumerate(dataset):\n",
        "          with tf.GradientTape() as tape:\n",
        "              predictions = model(input_seq)\n",
        "              loss = loss_function(target_seq, predictions)\n",
        "              \n",
        "          grads = tape.gradient(loss, model.variables)\n",
        "          optimizer.apply_gradients(zip(grads, model.variables))\n",
        "\n",
        "          if batch % 100 == 0:\n",
        "              print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n",
        "                                                            batch,\n",
        "                                                            loss))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
        "    print ('Time for epoch {} sec\\n'.format(time.time() - start))\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 3.6555\n",
            "Epoch 1 Batch 100 Loss 1.4778\n",
            "Epoch 1 Batch 200 Loss 1.2152\n",
            "Epoch 1 Loss 1.1898\n",
            "Time for epoch 21.053248643875122 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.1802\n",
            "Epoch 2 Batch 100 Loss 1.1568\n",
            "Epoch 2 Batch 200 Loss 1.0572\n",
            "Epoch 2 Loss 1.0927\n",
            "Time for epoch 21.905917167663574 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0893\n",
            "Epoch 3 Batch 100 Loss 1.0494\n",
            "Epoch 3 Batch 200 Loss 0.9870\n",
            "Epoch 3 Loss 1.0271\n",
            "Time for epoch 20.942824840545654 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.0359\n",
            "Epoch 4 Batch 100 Loss 1.0081\n",
            "Epoch 4 Batch 200 Loss 0.9988\n",
            "Epoch 4 Loss 1.0151\n",
            "Time for epoch 20.993561267852783 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.0065\n",
            "Epoch 5 Batch 100 Loss 0.9987\n",
            "Epoch 5 Batch 200 Loss 0.9767\n",
            "Epoch 5 Loss 1.0008\n",
            "Time for epoch 20.873497247695923 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.9984\n",
            "Epoch 6 Batch 100 Loss 1.0220\n",
            "Epoch 6 Batch 200 Loss 0.9416\n",
            "Epoch 6 Loss 0.9743\n",
            "Time for epoch 20.973227500915527 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.9995\n",
            "Epoch 7 Batch 100 Loss 1.0454\n",
            "Epoch 7 Batch 200 Loss 0.9078\n",
            "Epoch 7 Loss 0.9442\n",
            "Time for epoch 21.017024517059326 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.9461\n",
            "Epoch 8 Batch 100 Loss 0.9192\n",
            "Epoch 8 Batch 200 Loss 0.9603\n",
            "Epoch 8 Loss 0.9336\n",
            "Time for epoch 20.996238231658936 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.9617\n",
            "Epoch 9 Batch 100 Loss 0.9638\n",
            "Epoch 9 Batch 200 Loss 0.9393\n",
            "Epoch 9 Loss 0.9432\n",
            "Time for epoch 21.043195486068726 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.8993\n",
            "Epoch 10 Batch 100 Loss 0.9610\n",
            "Epoch 10 Batch 200 Loss 0.9206\n",
            "Epoch 10 Loss 0.9189\n",
            "Time for epoch 21.545292377471924 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0U_cmqGP8dwg",
        "colab_type": "code",
        "outputId": "a8b05fe9-fe95-4cce-8c63-90a9564db46b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt-5.data-00000-of-00001\n",
            "ckpt-10.data-00000-of-00001  ckpt-5.index\n",
            "ckpt-10.index\t\t     ckpt-6.data-00000-of-00001\n",
            "ckpt-1.data-00000-of-00001   ckpt-6.index\n",
            "ckpt-1.index\t\t     ckpt-7.data-00000-of-00001\n",
            "ckpt-2.data-00000-of-00001   ckpt-7.index\n",
            "ckpt-2.index\t\t     ckpt-8.data-00000-of-00001\n",
            "ckpt-3.data-00000-of-00001   ckpt-8.index\n",
            "ckpt-3.index\t\t     ckpt-9.data-00000-of-00001\n",
            "ckpt-4.data-00000-of-00001   ckpt-9.index\n",
            "ckpt-4.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0K3VLTVT81rt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is a hack to let us use the model with a different \n",
        "# batch size later\n",
        "model = Model(vocab_size, embedding_dim, units)\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Le_MRIFI1tRL",
        "colab_type": "code",
        "outputId": "d0ada8ef-3536-4842-d673-dd15a8e46c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation step (generating text using the learned model)\n",
        "\n",
        "# Number of characters to generate\n",
        "num_generate = max_length\n",
        "\n",
        "# You can change the start string to experiment\n",
        "start_string = random.choice(string.ascii_lowercase)\n",
        "\n",
        "# Converting our start string to numbers (vectorizing) \n",
        "input_eval = [char2idx[s] for s in start_string]\n",
        "input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "# Empty string to store our results\n",
        "text_generated = []\n",
        "\n",
        "# Low temperatures results in more predictable text.\n",
        "# Higher temperatures results in more surprising text.\n",
        "# Experiment to find the best setting.\n",
        "temperature = 0.5\n",
        "\n",
        "# Here batch size == 1\n",
        "model.reset_states()\n",
        "for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    # remove the batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # using a multinomial distribution to predict the word returned by the model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
        "    \n",
        "    # We pass the predicted word as the next input to the model\n",
        "    # along with the previous hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "    \n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "generated_color = start_string + ''.join(text_generated).replace('<pad>', '')\n",
        "print(generated_color)\n",
        "\n",
        "try:\n",
        "  parts = generated_color.split()\n",
        "  r = float(parts[-3])\n",
        "  g = float(parts[-2])\n",
        "  b = float(parts[-1])\n",
        "  plt.clf()\n",
        "  _ = plt.imshow([[(r, g, b)]])\n",
        "  _ = plt.axis('off')\n",
        "  _ = plt.title(generated_color, fontsize=18)\n",
        "except:\n",
        "  print('unable to parse color')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "janazeamary 1 2 2 1 1 1 1 16 1 19 25 24 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAFdCAYAAADfWaxGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n36EBYAz7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f13476edeb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2LSxcAKVBNLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}